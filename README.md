
---
title: Mod√®le de Pr√©diction des D√©missions (API FastAPI)
emoji: üìä
colorFrom: green
colorTo: blue
sdk: static 
app_file: main.py
---

# Projet Futurisys : D√©ploiement du Mod√®le Pr√©dictif de D√©missions

## 1. Pr√©sentation et Objectifs du Projet

L'objectif principal de ce projet r√©side dans l'op√©rationnalisation du mod√®le de Machine Learning d√©velopp√© lors du Projet 4. Ce mod√®le, con√ßu pour anticiper les risques de d√©mission au sein de l'effectif, est d√©sormais accessible via une API REST d√©velopp√©e avec le framework FastAPI.

La mise en ≈ìuvre de cette solution respecte des standards rigoureux de d√©veloppement logiciel afin de garantir la p√©rennit√© et la fiabilit√© du syst√®me :

* Performance et Efficacit√© : L'utilisation conjointe de FastAPI et du serveur ASGI Uvicorn assure un traitement asynchrone des requ√™tes, optimisant ainsi la latence et la charge serveur.

* Assurance Qualit√© (QA) : La stabilit√© du code est valid√©e par une suite de tests automatis√©s exhaustive via Pytest, garantissant la non-r√©gression et la fiabilit√© des fonctionnalit√©s.

* Tra√ßabilit√© et Audit : Un syst√®me de journalisation enregistre syst√©matiquement chaque pr√©diction dans une base de donn√©es PostgreSQL, permettant un audit ult√©rieur des d√©cisions du mod√®le.

* Automatisation (CI/CD) : L'int√©gration et le d√©ploiement continus sont assur√©s par GitHub Actions, automatisant les phases de test et de livraison logicielle.

## 2. Proc√©dures d'Installation et de Configuration (Environnement Local)

### 2.1. Pr√©requis Techniques

Le bon fonctionnement de l'application n√©cessite l'environnement suivant :

* Python 3.10 ou version ult√©rieure.

* Une instance de serveur **PostgreSQL** active (port par d√©faut : `5432`).

* Un r√¥le utilisateur PostgreSQL disposant des privil√®ges n√©cessaires √† la cr√©ation de bases de donn√©es (ex: `futurisys_user`).

### 2.2. Installation de l'Application

Veuillez suivre les √©tapes ci-dessous pour initialiser l'environnement de d√©veloppement :

```bash
# 1. Clonage du d√©p√¥t distant
git clone [https://votre-url-de-depot.com/futurisys_ml_api.git](https://votre-url-de-depot.com/futurisys_ml_api.git)
cd futurisys_ml_api

# 2. Cr√©ation et activation de l'environnement virtuel
python -m venv venv
source venv/bin/activate  # Sous Windows : venv\Scripts\activate

# 3. Installation des d√©pendances (Machine Learning et Base de Donn√©es)
pip install -r requirements.txt 
```


### 2.3. Configuration de la S√©curit√© et de la Base de Donn√©es

La gestion des identifiants sensibles est assur√©e par des variables d'environnement. Veuillez configurer le fichier `.env.example` en supprimant l'extension `.example` √† la racine du projet:

Configuration du fichier `.env` :

```bash
DB_USER=votre_utilisateur
DB_PASSWORD=votre_mot_de_passe_securise
DB_HOST=votre_adresse_serveur
DB_PORT=votre_port
DB_NAME=votre_base_de_donn√©e
```


Une fois la configuration √©tablie, ex√©cutez le script d'initialisation pour g√©n√©rer le sch√©ma de base de donn√©es :
```bash
python -m src.database.create_db
```

### 2.4. D√©marrage du Serveur API

Apr√®s la configuration de la base de donn√©es, d√©marrez le serveur d'application via la commande suivante :
```bash
python -m uvicorn main:app --reload --port 8000
```

L'interface de programmation est d√®s lors accessible √† l'adresse : `http://127.0.0.1:8000` si vous √™tes en local.

## 3. Guide d'Utilisation et Documentation de l'API

L'API expose un point de terminaison principal, `/predict`, lequel requiert un jeu de **22** variables caract√©ristiques d'un employ√© pour √©valuer la probabilit√© de d√©mission.

### 3.1. Documentation Technique (Swagger UI)

FastAPI g√©n√®re automatiquement une documentation interactive conforme aux sp√©cifications OpenAPI.
Acc√®s √† la documentation : `http://127.0.0.1:8000/docs`

Cette interface permet de consulter la structure attendue des donn√©es d'entr√©e (`DataInput`) ainsi que le format de la r√©ponse (`PredictionOutput`).

### 3.2. M√©canisme de Tra√ßabilit√© (Logging)

Afin de garantir la transparence et le suivi des op√©rations :

* Toute pr√©diction valid√©e entra√Æne l'archivage du r√©sultat et des donn√©es d'entr√©e associ√©es dans la table `ml_interactions`.

* Cette persistance des donn√©es est cruciale pour l'audit des performances du mod√®le et l'analyse comportementale des requ√™tes.

## 4. Architecture et Assurance Qualit√©

### 4.1. Strat√©gie de Gestion de Versions (Gitflow)

Le d√©veloppement suit la m√©thodologie **Gitflow** pour structurer le cycle de vie du logiciel :

* `main` : Branche de production, ne contenant que du code stable et valid√©.

* `develop` : Branche d'int√©gration principale pour les nouvelles fonctionnalit√©s.

* **Tags** (`v1.0.0`, etc.) : √âtiquetage rigoureux des versions publi√©es.

### 4.2. Pipeline d'Int√©gration et de D√©ploiement Continus (CI/CD)

Le pipeline **GitHub Actions** assure la conformit√© et la qualit√© du code :

* **Validation Automatis√©e** : L'ex√©cution de la suite de tests (**Pytest**) est d√©clench√©e syst√©matiquement lors des modifications sur la branche `develop`. La r√©ussite int√©grale des tests constitue une condition sine qua non pour la fusion du code.

* **D√©ploiement Contr√¥l√©** : Le processus de d√©ploiement en production est restreint √† la branche `main`, intervenant uniquement apr√®s validation d√©finitive.

## 5. Justifications Techniques et Analytiques

**Choix Technologiques**

* **FastAPI** et **SQLAlchemy** : Cette pile technologique a √©t√© s√©lectionn√©e pour ses performances √©lev√©es et sa gestion robuste de la concurrence (thread-safety) lors des transactions en base de donn√©es.

* **Seuil de D√©cision (0.5701)** : Le seuil optimal, d√©termin√© lors de la phase d'analyse exploratoire, a √©t√© int√©gr√© statiquement dans le module `model_loader.py`. Cette mesure vise √† maximiser le rappel (Recall), assurant ainsi une d√©tection efficace des profils √† risque.

**B√©n√©fices pour l'Analyse de Donn√©es**

L'archivage syst√©matique des interactions en base de donn√©es constitue un atout strat√©gique pour l'√©quipe Data. Cela permet notamment :

* Le suivi (monitoring) des performances du mod√®le en conditions r√©elles de production.

* L'analyse des distributions de donn√©es d'entr√©e afin de d√©tecter d'√©ventuelles d√©rives (**Data Drift**) dans les caract√©ristiques des nouveaux employ√©s.
